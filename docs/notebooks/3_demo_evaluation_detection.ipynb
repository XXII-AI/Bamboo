{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1418ef2",
   "metadata": {},
   "source": [
    "# Object Detection Evaluation\n",
    "\n",
    "This notebook aims at showing what kind of graph you can draw thank's to Lours evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f33081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:37:39.455811Z",
     "start_time": "2023-06-22T09:37:39.300085Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from lours.dataset import from_coco\n",
    "from lours.evaluation.detection import DetectionEvaluator as de\n",
    "from lours.evaluation.detection.util import display_confusion_matrix\n",
    "from lours.utils.grouper import ContinuousGroup\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed31c9d5",
   "metadata": {},
   "source": [
    "## Loading the dataset and the predictions\n",
    "\n",
    "Note that they are both treated as datasets at first, and only when creating the eval object we have a detection evaluator\n",
    "\n",
    "As a second Note, you can add several prediction datasets at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a0a657c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:37:39.930295Z",
     "start_time": "2023-06-22T09:37:39.412914Z"
    }
   },
   "outputs": [],
   "source": [
    "coco_eval = from_coco(\"notebook_data/coco_valid.json\").remap_from_preset(\n",
    "    \"coco\", \"supercategory\"\n",
    ")\n",
    "coco_darknet = from_coco(\n",
    "    \"notebook_data/yolov4_prediction_coco_eval.json\"\n",
    ").remap_from_preset(\"coco\", \"supercategory\")\n",
    "evaluator = de(\n",
    "    groundtruth=coco_eval, predictions=coco_darknet, predictions2=coco_darknet\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2dba7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:37:39.975835Z",
     "start_time": "2023-06-22T09:37:39.925023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1340eaaa32d438ba1d3421f7f6e9808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b> Evaluation object, containing 5,000 images, 36,781 groundtruth objects, and 2 p…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7d2b35",
   "metadata": {},
   "source": [
    "## Compute the matches\n",
    "\n",
    "This is arguably the slowest part.\n",
    "\n",
    "Hopefully, we can multiprocess it in the future\n",
    "\n",
    "You can compute them by taking category into account or not.\n",
    "\n",
    "- The category agnostic is useful for e.g. computing confusion matrices\n",
    "- The category specific is useful for e.g. computing precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f612ac81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:08.574292Z",
     "start_time": "2023-06-22T09:37:39.975615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing matches between groundtruth and predictions (category agnostic)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8313e445274fa48df3bc9e22226fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4979 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction_id</th>\n",
       "      <th>iou</th>\n",
       "      <th>groundtruth_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48019</td>\n",
       "      <td>0.954652</td>\n",
       "      <td>34646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48033</td>\n",
       "      <td>0.912193</td>\n",
       "      <td>104368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48034</td>\n",
       "      <td>0.939746</td>\n",
       "      <td>103487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48042</td>\n",
       "      <td>0.895466</td>\n",
       "      <td>230831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48020</td>\n",
       "      <td>0.922641</td>\n",
       "      <td>35802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>17979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>17980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>17981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>17982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>17983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85388 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction_id       iou  groundtruth_id\n",
       "0           48019  0.954652           34646\n",
       "1           48033  0.912193          104368\n",
       "2           48034  0.939746          103487\n",
       "3           48042  0.895466          230831\n",
       "4           48020  0.922641           35802\n",
       "..            ...       ...             ...\n",
       "60          17979  0.000000            <NA>\n",
       "61          17980  0.000000            <NA>\n",
       "62          17981  0.000000            <NA>\n",
       "63          17982  0.000000            <NA>\n",
       "64          17983  0.000000            <NA>\n",
       "\n",
       "[85388 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing matches between groundtruth and predictions (category specific)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae73360346b148089338d1a9ea0c7237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matches = evaluator.compute_matches(\"predictions\", category_agnostic=True)\n",
    "display(matches[\"predictions\"])\n",
    "matches = evaluator.compute_matches(\"predictions\", category_agnostic=False)\n",
    "display(matches[\"predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f24eae",
   "metadata": {},
   "source": [
    "See how two new tabs have been added to the dataset widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a911f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:08.664045Z",
     "start_time": "2023-06-22T09:38:08.617771Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf931a",
   "metadata": {},
   "source": [
    "Here, we just plot the IOU distribution. As you can see more than half the detections have a IoU of 0. These predictions typically have a very low confidence as well, which means they will be easily filtered and won't have a great influence on evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a292fe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:08.766849Z",
     "start_time": "2023-06-22T09:38:08.654621Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    evaluator.matches[\"category_specific\"][\"predictions\"][\"iou\"].sort_values().values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f54db00",
   "metadata": {},
   "source": [
    "### Computing confusion matrix\n",
    "\n",
    "The confusion matrix can be computed for all matches or by groups if the argument *groups* is defined.\n",
    "\n",
    "The values are normalized over the groundtruth.\n",
    "\n",
    "Notes:\n",
    "- The class *None* corresponds to the False Positive and False Negative.\n",
    "- The `model` indicated the name of given predictions. Here, we get the data for confusion for predictions named `predictions` and `predictions2` (which are the same, for the sake of the example)\n",
    "- Since matches have already been computed for `predictions` we only have to compute them for `predictions2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcecb002",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.013703Z",
     "start_time": "2023-06-22T09:38:08.767034Z"
    }
   },
   "outputs": [],
   "source": [
    "confusion_data = evaluator.compute_confusion_matrix()\n",
    "confusion_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfe9d89",
   "metadata": {},
   "source": [
    "### Display confusion matrix for prediction dataframe named \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d6324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.160715Z",
     "start_time": "2023-06-22T09:38:44.848955Z"
    }
   },
   "outputs": [],
   "source": [
    "display_confusion_matrix(\n",
    "    confusion_data.loc[confusion_data[\"model\"] == \"predictions\"].drop(columns=\"model\"),\n",
    "    title=\"All data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11887fe0",
   "metadata": {},
   "source": [
    "### Display confusion matrix for a specific group of prediction dataframe named \"predictions\"\n",
    "\n",
    "Here, we divide the evaluation dataset in 3 groups of equal size based on box_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad364adb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.248291Z",
     "start_time": "2023-06-22T09:38:45.140726Z"
    }
   },
   "outputs": [],
   "source": [
    "box_height_group = ContinuousGroup(name=\"box_height\", bins=3, qcut=True)\n",
    "confusion_data = evaluator.compute_confusion_matrix(\n",
    "    \"predictions\", groups=[box_height_group]\n",
    ")\n",
    "for (range_data, data), name in zip(\n",
    "    confusion_data.groupby(\"box_height\"), [\"small\", \"medium\", \"big\"]\n",
    "):\n",
    "    display_confusion_matrix(\n",
    "        data.drop(\"model\", axis=1),\n",
    "        title=(\n",
    "            f\"Confusion for {name} bounding boxes ({range_data.left:.1f}px to\"\n",
    "            f\" {range_data.right:.1f}px)\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c2a41",
   "metadata": {},
   "source": [
    "## Computing AP + Yolov5 metrics\n",
    "\n",
    "Here, we follow usual convention, by computing Average precision per class and per iou threshold.\n",
    "\n",
    "The we get the AP per category, the AP\\@0.5:0.95 per class and finally the mAP and the mAP\\@0.5:0.95\n",
    "\n",
    "see original code for yolov5 (if you dare) here : https://github.com/ultralytics/yolov5/blob/master/val.py\n",
    "\n",
    "Namely, In addition to AP and mAP, we want the precision\\@0.5 at best F1 score averaged over categories, and the recall\\@0.5 at best F1 score averaged over categories\n",
    "\n",
    "Notice, how we use the \"index column\" and \"index_values\" argument, to enforce that every category has the same confidence_threshold coordinates, i.e. 100 evenly spaced points between 0 and 1\n",
    "\n",
    "* `ious` are the different minimum iou values to consider a detection valid\n",
    "* `index_column` is the name of the value we want to use as index. This will force all values in the PR curve to be aligned. If not set, the resulting PR dataframe will no longer have aligned values, only where it actually changes, which depends on the category. This value can be `recall`, `precision` or `confidence_threshold`.\n",
    "* `index_values` are the values we want the curves to be aligned on. Typically, a set of increasing values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf261559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.821038Z",
     "start_time": "2023-06-22T09:38:45.452156Z"
    }
   },
   "outputs": [],
   "source": [
    "pr, ap = evaluator.compute_precision_recall(\n",
    "    predictions_names=\"predictions\",\n",
    "    ious=np.linspace(0.5, 0.95, 10).round(3),\n",
    "    index_column=None,\n",
    ")\n",
    "\n",
    "print(f\"mAP@0.5 = {ap[ap['iou_threshold'] == 0.5]['AP'].mean()}\")\n",
    "print(f\"mAP@0.5:0.95 = {ap['AP'].mean()}\")\n",
    "\n",
    "pr50, ap50 = evaluator.compute_precision_recall(\n",
    "    predictions_names=\"predictions\",\n",
    "    ious=0.5,\n",
    "    index_column=\"confidence_threshold\",\n",
    "    index_values=np.linspace(0, 1, 101),\n",
    "    f_scores_betas=(0.5, 1, 2),\n",
    ")\n",
    "\n",
    "\n",
    "# Note that next line would be invalid if we did not force the data points\n",
    "# to be aligned on the same confidence thresholds\n",
    "mean_f1 = pr50.groupby(\"confidence_threshold\").mean(numeric_only=True)\n",
    "best_mean_f1_score = mean_f1.loc[mean_f1[\"f1_score\"].idxmax()]\n",
    "print(\"F1 scores averaged over classes\")\n",
    "print(f\"best F1 = {best_mean_f1_score['f1_score']}\")\n",
    "print(f\"precision @ best F1 = {best_mean_f1_score['precision']}\")\n",
    "print(f\"recall @ best F1 = {best_mean_f1_score['recall']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c6211",
   "metadata": {},
   "source": [
    "Detailed view of Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6db8b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.869315Z",
     "start_time": "2023-06-22T09:38:45.821885Z"
    }
   },
   "outputs": [],
   "source": [
    "display(ap)\n",
    "ap_consolidated = pd.pivot_table(\n",
    "    ap, values=[\"AP\"], index=\"category_id\", columns=\"iou_threshold\"\n",
    ")\n",
    "ap_consolidated[\"mean\"] = ap_consolidated[\"AP\"].mean(axis=1)\n",
    "ap_consolidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a120d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:45.869469Z",
     "start_time": "2023-06-22T09:38:45.869049Z"
    }
   },
   "outputs": [],
   "source": [
    "mAP = ap_consolidated.mean(axis=0)\n",
    "mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5987f9d9",
   "metadata": {},
   "source": [
    "mAP\\@0.5:0.95 is thus equal to $0.510150$\n",
    "\n",
    "\n",
    "### Showing Curves\n",
    "\n",
    "Now we can show the PR curve to have a look at the precision vs recall for a particular class and different IOU values. Here is an example with class 2 (persons)\n",
    "\n",
    "First, we plot the different PR curves for different IOU threshold values,\n",
    "\n",
    "and then we plot the f1 score vs confidence_threshold.\n",
    "\n",
    "Finally, for an IoU threshold of 0.5, we plot recall, precision and F1_score vs confidence threshold\n",
    "\n",
    "#### Recall vs Precision vs IoU threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe8904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:46.141664Z",
     "start_time": "2023-06-22T09:38:45.869103Z"
    }
   },
   "outputs": [],
   "source": [
    "pr_persons = pr[pr[\"category_id\"] == 2]\n",
    "sns.relplot(\n",
    "    data=pr_persons,\n",
    "    x=\"recall\",\n",
    "    y=\"precision\",\n",
    "    hue=\"iou_threshold\",\n",
    "    kind=\"line\",\n",
    "    estimator=None,\n",
    "    sort=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e086772",
   "metadata": {},
   "source": [
    "#### F1 score vs confidence_threshold vs IoU threshold\n",
    "\n",
    "Notice how the optimal confidence threshold is lower with the IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d2fac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:46.339116Z",
     "start_time": "2023-06-22T09:38:46.094287Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=pr_persons,\n",
    "    x=\"confidence_threshold\",\n",
    "    y=\"f1_score\",\n",
    "    hue=\"iou_threshold\",\n",
    "    kind=\"line\",\n",
    "    estimator=None,\n",
    "    sort=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c5041",
   "metadata": {},
   "source": [
    "#### Precision, recall, $F_\\beta$ score \\@0.5 vs confidence threshold for persons\n",
    "Here, we graph recall, precision and F0.5, F1, and F2 with respect to confidence_threshold, for an IoU threshold of 0.5\n",
    "\n",
    "In addition, we annotate the confidence values where the F05, F1 and F2 scores are the highest, to show how each score weights precision and recall.\n",
    "\n",
    "Note that we don't use seaborn for this plot\n",
    "\n",
    "Side note, We can very clearly see that this set of predictions was cut off at a confidence threshold of 0.05\n",
    "\n",
    "We could lower that threshold, but it would dramatically increase the number of predictions without adding much information to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1f10a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:46.479500Z",
     "start_time": "2023-06-22T09:38:46.340194Z"
    }
   },
   "outputs": [],
   "source": [
    "to_plot = pr50[pr50[\"category_id\"] == 2].set_index(\"confidence_threshold\")\n",
    "\n",
    "f_scores = to_plot[[\"f1_score\", \"f0.5_score\", \"f2_score\"]]\n",
    "best_confidences = f_scores.idxmax()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "to_plot[[\"precision\", \"recall\"]].plot(ax=ax)\n",
    "to_plot[[\"f1_score\", \"f0.5_score\", \"f2_score\"]].plot(\n",
    "    style=[\"r--\", \"b--\", \"g--\"], ax=ax, linewidth=0.5\n",
    ")\n",
    "plt.scatter(f_scores.idxmax(), f_scores.max(), marker=\"+\")\n",
    "for x, y in zip(f_scores.idxmax(), f_scores.max()):\n",
    "    ax.annotate(\n",
    "        f\"{x:.2f}\",\n",
    "        [x + 0.01, y + 0.01],\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fbbee",
   "metadata": {},
   "source": [
    "## Computing grouped pr and ap curves\n",
    "\n",
    "Now is time to make things more interesting\n",
    "\n",
    "* `box_group` is how we want to split the data. Most usual group is `category_id`, but here we add the `box_height` group with 10 bins.\n",
    "  Be careful, the more groups you add, the more granular your curves become but the less data you have for each.\n",
    "* `image_group` is not used here but could be used the same as `box_groups` with e.g. weather condition or focal length\n",
    "\n",
    "Notice we don't use index alignment anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ce223f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:47.182215Z",
     "start_time": "2023-06-22T09:38:46.459873Z"
    }
   },
   "outputs": [],
   "source": [
    "from lours.utils.grouper import ContinuousGroup\n",
    "\n",
    "box_height_group = ContinuousGroup(name=\"box_height\", bins=10, qcut=True)\n",
    "pr, ap = evaluator.compute_precision_recall(\n",
    "    predictions_names=\"predictions\",\n",
    "    ious=(0.3, 0.5, 0.7, 0.9),\n",
    "    groups=[\"category_id\", box_height_group],\n",
    "    index_column=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9a7a2f",
   "metadata": {},
   "source": [
    "### Exploring the `pr` and `ap` DataFrames\n",
    "\n",
    "Each given group in the former function call will have its dedicated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ce935",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:47.195038Z",
     "start_time": "2023-06-22T09:38:47.181304Z"
    }
   },
   "outputs": [],
   "source": [
    "ap[(ap[\"iou_threshold\"] == 0.5) & (ap[\"category_id\"] == 1)].sort_values(\n",
    "    by=\"AP\"\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8107789c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:47.399819Z",
     "start_time": "2023-06-22T09:38:47.210284Z"
    }
   },
   "outputs": [],
   "source": [
    "pr[\n",
    "    (pr[\"category_id\"] == 2)\n",
    "    & (pr[\"iou_threshold\"] == 0.5)\n",
    "    & (pr[\"box_height\"].apply(lambda x: x.left) == 12.196)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad0b52",
   "metadata": {},
   "source": [
    "### Plotting Precision - Recall curves\n",
    "\n",
    "Here we used a filtered dataframe with only the 41 category and the easiest iou_threshold (0.5)\n",
    "notice the parameters `estimator=None` and `sort=False` to be able to plot vertical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d80738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:47.597671Z",
     "start_time": "2023-06-22T09:38:47.227247Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=pr[(pr[\"category_id\"] == 1) & (pr[\"iou_threshold\"] == 0.5)],\n",
    "    x=\"recall\",\n",
    "    y=\"precision\",\n",
    "    hue=\"box_height\",\n",
    "    kind=\"line\",\n",
    "    estimator=None,\n",
    "    sort=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7965d5",
   "metadata": {},
   "source": [
    "Here is a more complicated example for Persons (class id = 1, the most represented class, by far)\n",
    "\n",
    "colors and line styles can help you understand strengths and weakness of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852c25d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:47.844983Z",
     "start_time": "2023-06-22T09:38:47.476070Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=pr[(pr[\"category_id\"] == 1)],\n",
    "    x=\"recall\",\n",
    "    y=\"precision\",\n",
    "    hue=\"box_height\",\n",
    "    style=\"iou_threshold\",\n",
    "    kind=\"line\",\n",
    "    estimator=None,\n",
    "    sort=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ed569",
   "metadata": {},
   "source": [
    "## Getting Average Precision wrt to other parameters\n",
    "\n",
    "Usually, mean AP is just a single number giving you a general idea of the network quality.\n",
    "\n",
    "Here, we try to have a better understanding of the influence of some parameters.\n",
    "\n",
    "Namely here, we want to know if the network is better with small or large targets.\n",
    "\n",
    "Seaborn can let us visualise several dimensions at the same time like in the following graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad0660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:48.394865Z",
     "start_time": "2023-06-22T09:38:47.845182Z"
    }
   },
   "outputs": [],
   "source": [
    "data = ap.copy()\n",
    "data[\"box_mean_height\"] = data[\"box_height\"].apply(lambda x: x.mid)\n",
    "data[\"category_str\"] = data[\"category_id\"].replace(evaluator.label_map)\n",
    "display(data)\n",
    "g = sns.relplot(\n",
    "    data=data, x=\"box_mean_height\", y=\"AP\", kind=\"line\", hue=\"iou_threshold\"\n",
    ")\n",
    "g.set(xscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2fdc4",
   "metadata": {},
   "source": [
    "Former plot would present mean AP across all categories.\n",
    "\n",
    "The next (very large !) grid will let you see AP vs box height for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576b5df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:50.591823Z",
     "start_time": "2023-06-22T09:38:48.395803Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=data[data[\"iou_threshold\"] == 0.5],\n",
    "    x=\"box_mean_height\",\n",
    "    y=\"AP\",\n",
    "    col=\"category_str\",\n",
    "    col_wrap=4,\n",
    "    kind=\"line\",\n",
    ")\n",
    "g.set(xscale=\"log\")\n",
    "for axis in g.axes.flat:\n",
    "    axis.tick_params(labelbottom=True)\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85c0fed",
   "metadata": {},
   "source": [
    "## Dealing with more absolute metrics : target precision\n",
    "\n",
    "The next usecase aims at being closer to real life metrics than AP.\n",
    "\n",
    "In real world, AP is not that interesting because you ultimately have to choose a confidence threshold and thus a single point in the Precision/Recall curve. You will then have to make compromises between precision and recall.\n",
    "\n",
    "Here we are interested in a target precision. Given a wanted precision (because I want to minimize the fals positive) what Recall can I hope for ? Of course this problem can easily be transposed with a target recall and the corresponding precisions\n",
    "\n",
    "Next graphs shows an example where we want a precision of 60%. The recall values are where the different curves cross the horizontal line of value 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85310dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:50.781328Z",
     "start_time": "2023-06-22T09:38:50.592336Z"
    }
   },
   "outputs": [],
   "source": [
    "persons = pr[(pr[\"category_id\"] == 1) & (pr[\"iou_threshold\"] == 0.5)]\n",
    "plt.figure(figsize=(7, 7))\n",
    "precision = plt.plot([0, 1], [0.6, 0.6], label=\"precision @0.6\", linestyle=\"--\")\n",
    "pl = sns.lineplot(\n",
    "    data=persons,\n",
    "    x=\"recall\",\n",
    "    y=\"precision\",\n",
    "    hue=\"box_height\",\n",
    "    estimator=None,\n",
    "    sort=False,\n",
    "    palette=\"bright\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ed2d78",
   "metadata": {},
   "source": [
    "For this example, we want the recall values for 10 different wanted precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4eef9d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:50.781415Z",
     "start_time": "2023-06-22T09:38:50.745745Z"
    }
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "\n",
    "def interpolate_precision(data, value):\n",
    "    if isinstance(value, float):\n",
    "        value = [value]\n",
    "    recall_values = np.interp(\n",
    "        value, xp=data[\"precision\"][::-1], fp=data[\"recall\"][::-1]\n",
    "    )\n",
    "    recall_values = pd.Series(\n",
    "        recall_values, index=pd.Index(value, name=\"target_precision\"), name=\"recall\"\n",
    "    ).to_frame()\n",
    "    return recall_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ed310",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:50.797038Z",
     "start_time": "2023-06-22T09:38:50.755719Z"
    }
   },
   "outputs": [],
   "source": [
    "recall_at_precision_persons = persons.groupby(\"box_height\").apply(\n",
    "    partial(interpolate_precision, value=np.linspace(0.1, 0.9, 5).round(3)),\n",
    "    include_groups=False,\n",
    ")\n",
    "recall_at_precision_persons = recall_at_precision_persons.reset_index()\n",
    "recall_at_precision_persons[\"box_mean_height\"] = recall_at_precision_persons[\n",
    "    \"box_height\"\n",
    "].apply(lambda x: x.mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23360c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:51.031779Z",
     "start_time": "2023-06-22T09:38:50.796990Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=recall_at_precision_persons,\n",
    "    x=\"box_mean_height\",\n",
    "    hue=\"target_precision\",\n",
    "    y=\"recall\",\n",
    "    kind=\"line\",\n",
    ")\n",
    "g.set(xscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a44272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:51.290093Z",
     "start_time": "2023-06-22T09:38:51.032788Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=recall_at_precision_persons,\n",
    "    x=\"target_precision\",\n",
    "    hue=\"box_height\",\n",
    "    y=\"recall\",\n",
    "    kind=\"line\",\n",
    "    palette=\"bright\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f1e946",
   "metadata": {},
   "source": [
    "Next example covers all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13516ec3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:51.342913Z",
     "start_time": "2023-06-22T09:38:51.290975Z"
    }
   },
   "outputs": [],
   "source": [
    "all_classes_iou_05 = pr[pr[\"iou_threshold\"] == 0.5]\n",
    "recall_at_precision = all_classes_iou_05.groupby([\"box_height\", \"category_id\"]).apply(\n",
    "    partial(interpolate_precision, value=np.linspace(0.1, 0.9, 5).round(2)),\n",
    "    include_groups=False,\n",
    ")\n",
    "recall_at_precision = recall_at_precision.reset_index()\n",
    "recall_at_precision[\"box_mean_height\"] = recall_at_precision[\"box_height\"].apply(\n",
    "    lambda x: x.mid\n",
    ")\n",
    "recall_at_precision[\"category_str\"] = recall_at_precision[\"category_id\"].replace(\n",
    "    evaluator.label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caad849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:51.906076Z",
     "start_time": "2023-06-22T09:38:51.321315Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=recall_at_precision,\n",
    "    x=\"target_precision\",\n",
    "    hue=\"box_height\",\n",
    "    y=\"recall\",\n",
    "    kind=\"line\",\n",
    "    palette=\"bright\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d64549",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:52.558506Z",
     "start_time": "2023-06-22T09:38:51.906527Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=recall_at_precision,\n",
    "    x=\"box_mean_height\",\n",
    "    hue=\"target_precision\",\n",
    "    y=\"recall\",\n",
    "    kind=\"line\",\n",
    "    palette=\"bright\",\n",
    ")\n",
    "g.set(xscale=\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f5f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T09:38:55.067652Z",
     "start_time": "2023-06-22T09:38:52.559991Z"
    }
   },
   "outputs": [],
   "source": [
    "g = sns.relplot(\n",
    "    data=recall_at_precision,\n",
    "    x=\"box_mean_height\",\n",
    "    hue=\"target_precision\",\n",
    "    y=\"recall\",\n",
    "    col=\"category_str\",\n",
    "    col_wrap=4,\n",
    "    kind=\"line\",\n",
    "    palette=\"bright\",\n",
    ")\n",
    "g.set(xscale=\"log\")\n",
    "for axis in g.axes.flat:\n",
    "    axis.tick_params(labelbottom=True)\n",
    "plt.subplots_adjust(hspace=0.15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "abc9a1dac9bd8889ac80f2172f7e9696d54384b48ab3353122145881864117fe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "02f93a62366347e3a5479279d8804283": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "10b45e2a01a144298c3c716bfa90717d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "17fb4bdf25d0411fb4c7212ec0e4db3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1ce358ce7715497f9da51161adfb448f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "27f00536e4544328aea0e0bd87d1668a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9ecbe5bd49ee4eadb44a0f55171c108e",
       "style": "IPY_MODEL_b2d56018c19645e3be48129f823c55ad",
       "value": " 6832/14503 [00:21&lt;00:27, 276.50it/s]"
      }
     },
     "2a8c70f673504e07899e6ca00f9cecb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2d642515e5c641e9b2be0980b45f8caa": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_f08721efc82346caaa13c24970635bd8",
       "outputs": [
        {
         "data": {
          "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>width</th>\n      <th>height</th>\n      <th>relative_path</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>352582</th>\n      <td>425</td>\n      <td>640</td>\n      <td>Images/valid/000000352582.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>113354</th>\n      <td>640</td>\n      <td>480</td>\n      <td>Images/valid/000000113354.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>58393</th>\n      <td>640</td>\n      <td>486</td>\n      <td>Images/valid/000000058393.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>147729</th>\n      <td>500</td>\n      <td>375</td>\n      <td>Images/valid/000000147729.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>310072</th>\n      <td>640</td>\n      <td>383</td>\n      <td>Images/valid/000000310072.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>311180</th>\n      <td>480</td>\n      <td>640</td>\n      <td>Images/valid/000000311180.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>302030</th>\n      <td>640</td>\n      <td>359</td>\n      <td>Images/valid/000000302030.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>105455</th>\n      <td>427</td>\n      <td>640</td>\n      <td>Images/valid/000000105455.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>428280</th>\n      <td>500</td>\n      <td>333</td>\n      <td>Images/valid/000000428280.jpg</td>\n      <td>.jpg</td>\n    </tr>\n    <tr>\n      <th>349837</th>\n      <td>500</td>\n      <td>333</td>\n      <td>Images/valid/000000349837.jpg</td>\n      <td>.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>5000 rows × 4 columns</p>\n</div>",
          "text/plain": "        width  height                  relative_path  type\nid                                                        \n352582    425     640  Images/valid/000000352582.jpg  .jpg\n113354    640     480  Images/valid/000000113354.jpg  .jpg\n58393     640     486  Images/valid/000000058393.jpg  .jpg\n147729    500     375  Images/valid/000000147729.jpg  .jpg\n310072    640     383  Images/valid/000000310072.jpg  .jpg\n...       ...     ...                            ...   ...\n311180    480     640  Images/valid/000000311180.jpg  .jpg\n302030    640     359  Images/valid/000000302030.jpg  .jpg\n105455    427     640  Images/valid/000000105455.jpg  .jpg\n428280    500     333  Images/valid/000000428280.jpg  .jpg\n349837    500     333  Images/valid/000000349837.jpg  .jpg\n\n[5000 rows x 4 columns]"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "2f92d79c3914488baaecc9915a2d4d42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "382b772d129044c4a8d143c83d5f635c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "41395e5b5c4f4cf2a9193ea8d952fe4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "470f75e2ac12499191e687771ba89a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "48a21b9cc7ee42daafa0ac87f0471a7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_02f93a62366347e3a5479279d8804283",
       "style": "IPY_MODEL_382b772d129044c4a8d143c83d5f635c",
       "value": " 47%"
      }
     },
     "5124d2886e024aac8d2151dfe88107bc": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_9db2063e92784c4cbf2dfaed773ac64d",
       "outputs": [
        {
         "data": {
          "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category string</th>\n    </tr>\n    <tr>\n      <th>categorty_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>person</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vehicle</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>outdoor</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>animal</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>accessory</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>sports</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>kitchen</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>food</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>furniture</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>electronic</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>appliance</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>indoor</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
          "text/plain": "             category string\ncategorty_id                \n1                     person\n2                    vehicle\n3                    outdoor\n4                     animal\n5                  accessory\n6                     sports\n7                    kitchen\n8                       food\n9                  furniture\n10                electronic\n11                 appliance\n12                    indoor"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "788f1f9afb9c4f16a3606f55522041b4": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_b70b3c9feba547dd9ccaeb8efdde6a5f",
       "outputs": [
        {
         "data": {
          "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>category_str</th>\n      <th>category_id</th>\n      <th>split</th>\n      <th>box_x_min</th>\n      <th>box_y_min</th>\n      <th>box_width</th>\n      <th>box_height</th>\n      <th>confidence</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>352582</td>\n      <td>sports</td>\n      <td>6</td>\n      <td>eval</td>\n      <td>173.500088</td>\n      <td>422.783040</td>\n      <td>84.095175</td>\n      <td>42.128000</td>\n      <td>0.993809</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>352582</td>\n      <td>vehicle</td>\n      <td>2</td>\n      <td>eval</td>\n      <td>374.986850</td>\n      <td>393.807360</td>\n      <td>50.852950</td>\n      <td>32.784640</td>\n      <td>0.567461</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>352582</td>\n      <td>vehicle</td>\n      <td>2</td>\n      <td>eval</td>\n      <td>374.986850</td>\n      <td>393.807360</td>\n      <td>50.852950</td>\n      <td>32.784640</td>\n      <td>0.298446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>eval</td>\n      <td>96.376400</td>\n      <td>185.985280</td>\n      <td>256.949900</td>\n      <td>459.486720</td>\n      <td>0.992746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>eval</td>\n      <td>0.072887</td>\n      <td>250.966720</td>\n      <td>76.917775</td>\n      <td>385.540480</td>\n      <td>0.762402</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>84056</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>15.557250</td>\n      <td>102.709521</td>\n      <td>57.678500</td>\n      <td>165.555612</td>\n      <td>0.985206</td>\n    </tr>\n    <tr>\n      <th>84057</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>232.229250</td>\n      <td>28.451520</td>\n      <td>113.910500</td>\n      <td>306.236790</td>\n      <td>0.974466</td>\n    </tr>\n    <tr>\n      <th>84058</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>333.614000</td>\n      <td>9.807183</td>\n      <td>127.360000</td>\n      <td>326.742930</td>\n      <td>0.972766</td>\n    </tr>\n    <tr>\n      <th>84059</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>458.771750</td>\n      <td>24.938204</td>\n      <td>41.755500</td>\n      <td>295.568469</td>\n      <td>0.904706</td>\n    </tr>\n    <tr>\n      <th>84060</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>-0.166000</td>\n      <td>59.784156</td>\n      <td>16.650000</td>\n      <td>183.867948</td>\n      <td>0.772212</td>\n    </tr>\n  </tbody>\n</table>\n<p>84061 rows × 9 columns</p>\n</div>",
          "text/plain": "       image_id category_str  category_id split   box_x_min   box_y_min  \\\nid                                                                        \n0        352582       sports            6  eval  173.500088  422.783040   \n1        352582      vehicle            2  eval  374.986850  393.807360   \n2        352582      vehicle            2  eval  374.986850  393.807360   \n3        352582       person            1  eval   96.376400  185.985280   \n4        352582       person            1  eval    0.072887  250.966720   \n...         ...          ...          ...   ...         ...         ...   \n84056    349837    appliance           11  eval   15.557250  102.709521   \n84057    349837    appliance           11  eval  232.229250   28.451520   \n84058    349837    appliance           11  eval  333.614000    9.807183   \n84059    349837    appliance           11  eval  458.771750   24.938204   \n84060    349837    appliance           11  eval   -0.166000   59.784156   \n\n        box_width  box_height  confidence  \nid                                         \n0       84.095175   42.128000    0.993809  \n1       50.852950   32.784640    0.567461  \n2       50.852950   32.784640    0.298446  \n3      256.949900  459.486720    0.992746  \n4       76.917775  385.540480    0.762402  \n...           ...         ...         ...  \n84056   57.678500  165.555612    0.985206  \n84057  113.910500  306.236790    0.974466  \n84058  127.360000  326.742930    0.972766  \n84059   41.755500  295.568469    0.904706  \n84060   16.650000  183.867948    0.772212  \n\n[84061 rows x 9 columns]"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "8cb64832f8c648b39befc52303293a1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9c6f1f5e57a44584ab85200723bf29ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9db2063e92784c4cbf2dfaed773ac64d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9ecbe5bd49ee4eadb44a0f55171c108e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a1a8952dfe9d4de688ea676621e66eae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a4f3939c67264382ad1b09cc1508f767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_b9900cdb95184867a21b72f523032174",
       "max": 4979,
       "style": "IPY_MODEL_a1a8952dfe9d4de688ea676621e66eae",
       "value": 4979
      }
     },
     "aa255e02464345dd885e3155446b712d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_8cb64832f8c648b39befc52303293a1e",
       "style": "IPY_MODEL_470f75e2ac12499191e687771ba89a3f",
       "value": "<b> Evaluation object, containing 5,000 images, 36,781 groundtruth objects, and 2 prediction sets </b>"
      }
     },
     "ae73360346b148089338d1a9ea0c7237": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_48a21b9cc7ee42daafa0ac87f0471a7d",
        "IPY_MODEL_e1417c77cadf4c0589676f3d9119201e",
        "IPY_MODEL_27f00536e4544328aea0e0bd87d1668a"
       ],
       "layout": "IPY_MODEL_10b45e2a01a144298c3c716bfa90717d"
      }
     },
     "b2d56018c19645e3be48129f823c55ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b70b3c9feba547dd9ccaeb8efdde6a5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b9900cdb95184867a21b72f523032174": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ba243a40165a4eaaa14001ede688249f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_efd69a8c6f1840f7a705e37c59cecd2a",
       "style": "IPY_MODEL_17fb4bdf25d0411fb4c7212ec0e4db3e",
       "value": " 4979/4979 [00:24&lt;00:00, 229.56it/s]"
      }
     },
     "be8313e445274fa48df3bc9e22226fc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_f52d246406954962bb788f21351c3cb1",
        "IPY_MODEL_a4f3939c67264382ad1b09cc1508f767",
        "IPY_MODEL_ba243a40165a4eaaa14001ede688249f"
       ],
       "layout": "IPY_MODEL_41395e5b5c4f4cf2a9193ea8d952fe4a"
      }
     },
     "ce5e2e8ed287438a8c7389b21f44b078": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "TabModel",
      "state": {
       "children": [
        "IPY_MODEL_2d642515e5c641e9b2be0980b45f8caa",
        "IPY_MODEL_e35bc29b06e4413eaa31cba4e86b63a9",
        "IPY_MODEL_788f1f9afb9c4f16a3606f55522041b4",
        "IPY_MODEL_f87b5d76c0014809920440c6b42cd927",
        "IPY_MODEL_5124d2886e024aac8d2151dfe88107bc"
       ],
       "layout": "IPY_MODEL_ffea458d6edc4ef680fe9cb36ed8b4af",
       "selected_index": 0,
       "titles": [
        "Images",
        "Groundtruth",
        "predictions",
        "predictions2",
        "label_map"
       ]
      }
     },
     "cf6675d6c9f643e6845a1e025deb9392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e1340eaaa32d438ba1d3421f7f6e9808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_aa255e02464345dd885e3155446b712d",
        "IPY_MODEL_ce5e2e8ed287438a8c7389b21f44b078"
       ],
       "layout": "IPY_MODEL_2f92d79c3914488baaecc9915a2d4d42"
      }
     },
     "e1417c77cadf4c0589676f3d9119201e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_9c6f1f5e57a44584ab85200723bf29ba",
       "max": 14503,
       "style": "IPY_MODEL_1ce358ce7715497f9da51161adfb448f",
       "value": 6832
      }
     },
     "e35bc29b06e4413eaa31cba4e86b63a9": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_cf6675d6c9f643e6845a1e025deb9392",
       "outputs": [
        {
         "data": {
          "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>category_str</th>\n      <th>category_id</th>\n      <th>split</th>\n      <th>box_x_min</th>\n      <th>box_y_min</th>\n      <th>box_width</th>\n      <th>box_height</th>\n      <th>area</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>460450</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>valid</td>\n      <td>112.43</td>\n      <td>195.32</td>\n      <td>214.78</td>\n      <td>438.19</td>\n      <td>48685.67910</td>\n    </tr>\n    <tr>\n      <th>535917</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>valid</td>\n      <td>0.00</td>\n      <td>256.00</td>\n      <td>80.54</td>\n      <td>376.81</td>\n      <td>22650.73800</td>\n    </tr>\n    <tr>\n      <th>602093</th>\n      <td>352582</td>\n      <td>sports</td>\n      <td>6</td>\n      <td>valid</td>\n      <td>171.63</td>\n      <td>424.03</td>\n      <td>85.89</td>\n      <td>40.67</td>\n      <td>2605.72090</td>\n    </tr>\n    <tr>\n      <th>589077</th>\n      <td>113354</td>\n      <td>animal</td>\n      <td>4</td>\n      <td>valid</td>\n      <td>260.99</td>\n      <td>158.88</td>\n      <td>141.52</td>\n      <td>194.11</td>\n      <td>9978.94125</td>\n    </tr>\n    <tr>\n      <th>589740</th>\n      <td>113354</td>\n      <td>animal</td>\n      <td>4</td>\n      <td>valid</td>\n      <td>366.49</td>\n      <td>174.59</td>\n      <td>115.67</td>\n      <td>142.71</td>\n      <td>5784.68620</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>331107</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>valid</td>\n      <td>66.00</td>\n      <td>94.87</td>\n      <td>71.25</td>\n      <td>194.26</td>\n      <td>12029.44125</td>\n    </tr>\n    <tr>\n      <th>332788</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>valid</td>\n      <td>138.00</td>\n      <td>62.63</td>\n      <td>98.25</td>\n      <td>252.00</td>\n      <td>23037.46875</td>\n    </tr>\n    <tr>\n      <th>333394</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>valid</td>\n      <td>234.44</td>\n      <td>29.87</td>\n      <td>113.49</td>\n      <td>298.65</td>\n      <td>30406.51295</td>\n    </tr>\n    <tr>\n      <th>333685</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>valid</td>\n      <td>335.04</td>\n      <td>10.48</td>\n      <td>125.17</td>\n      <td>318.78</td>\n      <td>37187.97840</td>\n    </tr>\n    <tr>\n      <th>333731</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>valid</td>\n      <td>460.39</td>\n      <td>0.00</td>\n      <td>39.61</td>\n      <td>328.64</td>\n      <td>12492.52165</td>\n    </tr>\n  </tbody>\n</table>\n<p>36781 rows × 9 columns</p>\n</div>",
          "text/plain": "        image_id category_str  category_id  split  box_x_min  box_y_min  \\\nid                                                                        \n460450    352582       person            1  valid     112.43     195.32   \n535917    352582       person            1  valid       0.00     256.00   \n602093    352582       sports            6  valid     171.63     424.03   \n589077    113354       animal            4  valid     260.99     158.88   \n589740    113354       animal            4  valid     366.49     174.59   \n...          ...          ...          ...    ...        ...        ...   \n331107    349837    appliance           11  valid      66.00      94.87   \n332788    349837    appliance           11  valid     138.00      62.63   \n333394    349837    appliance           11  valid     234.44      29.87   \n333685    349837    appliance           11  valid     335.04      10.48   \n333731    349837    appliance           11  valid     460.39       0.00   \n\n        box_width  box_height         area  \nid                                          \n460450     214.78      438.19  48685.67910  \n535917      80.54      376.81  22650.73800  \n602093      85.89       40.67   2605.72090  \n589077     141.52      194.11   9978.94125  \n589740     115.67      142.71   5784.68620  \n...           ...         ...          ...  \n331107      71.25      194.26  12029.44125  \n332788      98.25      252.00  23037.46875  \n333394     113.49      298.65  30406.51295  \n333685     125.17      318.78  37187.97840  \n333731      39.61      328.64  12492.52165  \n\n[36781 rows x 9 columns]"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "ee137291f0b846498e172656b7b5ea13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "efd69a8c6f1840f7a705e37c59cecd2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f08721efc82346caaa13c24970635bd8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f52d246406954962bb788f21351c3cb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ee137291f0b846498e172656b7b5ea13",
       "style": "IPY_MODEL_f81d718550fd4fee974b001d451b825d",
       "value": "100%"
      }
     },
     "f81d718550fd4fee974b001d451b825d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f87b5d76c0014809920440c6b42cd927": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_2a8c70f673504e07899e6ca00f9cecb2",
       "outputs": [
        {
         "data": {
          "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>category_str</th>\n      <th>category_id</th>\n      <th>split</th>\n      <th>box_x_min</th>\n      <th>box_y_min</th>\n      <th>box_width</th>\n      <th>box_height</th>\n      <th>confidence</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>352582</td>\n      <td>sports</td>\n      <td>6</td>\n      <td>eval</td>\n      <td>173.500088</td>\n      <td>422.783040</td>\n      <td>84.095175</td>\n      <td>42.128000</td>\n      <td>0.993809</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>352582</td>\n      <td>vehicle</td>\n      <td>2</td>\n      <td>eval</td>\n      <td>374.986850</td>\n      <td>393.807360</td>\n      <td>50.852950</td>\n      <td>32.784640</td>\n      <td>0.567461</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>352582</td>\n      <td>vehicle</td>\n      <td>2</td>\n      <td>eval</td>\n      <td>374.986850</td>\n      <td>393.807360</td>\n      <td>50.852950</td>\n      <td>32.784640</td>\n      <td>0.298446</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>eval</td>\n      <td>96.376400</td>\n      <td>185.985280</td>\n      <td>256.949900</td>\n      <td>459.486720</td>\n      <td>0.992746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>352582</td>\n      <td>person</td>\n      <td>1</td>\n      <td>eval</td>\n      <td>0.072887</td>\n      <td>250.966720</td>\n      <td>76.917775</td>\n      <td>385.540480</td>\n      <td>0.762402</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>84056</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>15.557250</td>\n      <td>102.709521</td>\n      <td>57.678500</td>\n      <td>165.555612</td>\n      <td>0.985206</td>\n    </tr>\n    <tr>\n      <th>84057</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>232.229250</td>\n      <td>28.451520</td>\n      <td>113.910500</td>\n      <td>306.236790</td>\n      <td>0.974466</td>\n    </tr>\n    <tr>\n      <th>84058</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>333.614000</td>\n      <td>9.807183</td>\n      <td>127.360000</td>\n      <td>326.742930</td>\n      <td>0.972766</td>\n    </tr>\n    <tr>\n      <th>84059</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>458.771750</td>\n      <td>24.938204</td>\n      <td>41.755500</td>\n      <td>295.568469</td>\n      <td>0.904706</td>\n    </tr>\n    <tr>\n      <th>84060</th>\n      <td>349837</td>\n      <td>appliance</td>\n      <td>11</td>\n      <td>eval</td>\n      <td>-0.166000</td>\n      <td>59.784156</td>\n      <td>16.650000</td>\n      <td>183.867948</td>\n      <td>0.772212</td>\n    </tr>\n  </tbody>\n</table>\n<p>84061 rows × 9 columns</p>\n</div>",
          "text/plain": "       image_id category_str  category_id split   box_x_min   box_y_min  \\\nid                                                                        \n0        352582       sports            6  eval  173.500088  422.783040   \n1        352582      vehicle            2  eval  374.986850  393.807360   \n2        352582      vehicle            2  eval  374.986850  393.807360   \n3        352582       person            1  eval   96.376400  185.985280   \n4        352582       person            1  eval    0.072887  250.966720   \n...         ...          ...          ...   ...         ...         ...   \n84056    349837    appliance           11  eval   15.557250  102.709521   \n84057    349837    appliance           11  eval  232.229250   28.451520   \n84058    349837    appliance           11  eval  333.614000    9.807183   \n84059    349837    appliance           11  eval  458.771750   24.938204   \n84060    349837    appliance           11  eval   -0.166000   59.784156   \n\n        box_width  box_height  confidence  \nid                                         \n0       84.095175   42.128000    0.993809  \n1       50.852950   32.784640    0.567461  \n2       50.852950   32.784640    0.298446  \n3      256.949900  459.486720    0.992746  \n4       76.917775  385.540480    0.762402  \n...           ...         ...         ...  \n84056   57.678500  165.555612    0.985206  \n84057  113.910500  306.236790    0.974466  \n84058  127.360000  326.742930    0.972766  \n84059   41.755500  295.568469    0.904706  \n84060   16.650000  183.867948    0.772212  \n\n[84061 rows x 9 columns]"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ]
      }
     },
     "ffea458d6edc4ef680fe9cb36ed8b4af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
